#!/bin/bash

# Script pour exÃ©cuter le transformateur mÃ©tÃ©o Spark

echo "=========================================="
echo "DÃ©marrage du transformateur mÃ©tÃ©o Spark"
echo "=========================================="
echo ""

# VÃ©rifier que les services sont en cours d'exÃ©cution
if ! docker ps | grep -q kafka; then
    echo "âŒ Erreur: Le conteneur Kafka n'est pas en cours d'exÃ©cution."
    echo "Veuillez dÃ©marrer les services avec: docker-compose up -d"
    exit 1
fi

if ! docker ps | grep -q pyspark_notebook; then
    echo "âŒ Erreur: Le conteneur pyspark_notebook n'est pas en cours d'exÃ©cution."
    echo "Veuillez dÃ©marrer les services avec: docker-compose up -d"
    exit 1
fi

# CrÃ©er le topic weather_transformed si nÃ©cessaire
echo "ğŸ“‹ VÃ©rification du topic weather_transformed..."
./create_transformed_topic.sh
echo ""

# Nettoyer les anciens checkpoints pour Ã©viter les conflits
echo "ğŸ§¹ Nettoyage des anciens checkpoints..."
docker exec pyspark_notebook bash -c "rm -rf /tmp/checkpoint/weather_transformer*" 2>/dev/null
echo "âœ… Checkpoints nettoyÃ©s"
echo ""

# Copier le script dans le conteneur
echo "ğŸ“¦ Copie du script dans le conteneur Spark..."
docker cp weather_transformer.py pyspark_notebook:/home/jovyan/work/weather_transformer.py

# ExÃ©cuter le transformateur dans le conteneur
echo "ğŸš€ DÃ©marrage du transformateur..."
echo "   (Appuyez sur Ctrl+C pour arrÃªter)"
echo ""

# Utiliser spark-submit pour exÃ©cuter le script PySpark
# Note: Le package Kafka sera tÃ©lÃ©chargÃ© automatiquement au premier lancement
docker exec -it pyspark_notebook \
  /usr/local/spark/bin/spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
  --master local[*] \
  --conf spark.sql.streaming.checkpointLocation=/tmp/checkpoint/weather_transformer \
  /home/jovyan/work/weather_transformer.py \
  --kafka-servers kafka:9092 \
  --input-topic weather_stream \
  --output-topic weather_transformed
