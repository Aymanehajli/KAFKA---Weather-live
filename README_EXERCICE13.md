# Exercice 13 : D√©tection d'anomalies climatiques (Batch vs Speed)

## üìã Objectif

Impl√©menter un syst√®me de d√©tection d'anomalies climatiques en temps r√©el qui combine :
- **Speed Layer** : Donn√©es temps r√©el depuis Kafka (`weather_transformed`)
- **Batch Layer** : Profils saisonniers historiques depuis HDFS
- **Jointure Batch vs Speed** : Comparaison en temps r√©el pour d√©tecter les anomalies

## üéØ Fonctionnalit√©s

### 1. Ingestion des donn√©es

#### Speed Layer (Temps r√©el)
- Lecture en streaming depuis le topic Kafka `weather_transformed`
- Donn√©es m√©t√©orologiques en temps r√©el avec alertes

#### Batch Layer (Historique)
- Chargement des profils saisonniers enrichis depuis HDFS
- Structure : `/hdfs-data/{country}/{city}/seasonal_profile_enriched/{year}/profile.json`
- Profils mensuels avec statistiques (moyenne, √©cart-type, quantiles)

### 2. Jointure Batch vs Speed

**Cl√© de jointure** : `{country, city, month}`

**Colonnes de r√©f√©rence utilis√©es** :
- `avg_temperature` : Temp√©rature moyenne historique
- `avg_windspeed` : Vitesse de vent moyenne historique
- `std_temperature` : √âcart-type de la temp√©rature
- `std_windspeed` : √âcart-type du vent
- `alert_probability` : Probabilit√© historique d'alerte
- Quantiles (Q25, m√©diane, Q75) pour d√©tection avanc√©e

### 3. D√©finition des seuils d'anomalie

#### Temp√©rature
- **Anomalie si** :
  - √âcart absolu > **5¬∞C** (configurable)
  - **OU** √©cart > **2 √©carts-types** de la moyenne historique
- **Types d'anomalies** :
  - `heat_wave` : Temp√©rature anormalement √©lev√©e
  - `cold_spell` : Temp√©rature anormalement basse

#### Vent
- **Anomalie si** :
  - D√©passe la moyenne historique de **2 √©carts-types** (configurable)
- **Type d'anomalie** :
  - `wind_storm` : Vent anormalement fort

#### Alertes
- **Anomalie si** :
  - Alerte d√©tect√©e (level_1 ou level_2) **ET** probabilit√© historique < 10%
- **Type d'anomalie** :
  - `unexpected_alert` : Alerte inattendue selon l'historique

### 4. D√©tection en streaming avec Spark

Le job Spark Structured Streaming :
1. Lit en continu depuis `weather_transformed`
2. Joint avec les profils historiques charg√©s au d√©marrage
3. Calcule les √©carts en temps r√©el
4. D√©tecte les anomalies selon les seuils
5. Produit un champ `is_anomaly` (bool√©en)
6. Produit un champ `anomaly_type` (textuel)

### 5. M√©tadonn√©es des anomalies

Chaque anomalie d√©tect√©e contient :
- `event_time` : Timestamp de l'√©v√©nement
- `city` : Ville
- `country` : Pays
- `variable` : Type de variable (temperature, windspeed, alert)
- `observed_value` : Valeur observ√©e
- `expected_value` : Valeur attendue (moyenne historique)
- `anomaly_type` : Type d'anomalie (heat_wave, cold_spell, wind_storm, unexpected_alert)

### 6. Publication des anomalies

#### Topic Kafka : `weather_anomalies`

**Format JSON** :
```json
{
  "event_time": "2025-09-23T15:00:00Z",
  "city": "Paris",
  "country": "France",
  "variable": "temperature",
  "observed_value": 30.0,
  "expected_value": 18.0,
  "anomaly_type": "heat_wave"
}
```

### 7. Sauvegarde dans HDFS

**Structure** : `/hdfs-data/{country}/{city}/anomalies/{year}/{month}/anomalies.json`

**Format** :
```json
{
  "country": "France",
  "city": "Paris",
  "year": 2025,
  "month": 9,
  "anomalies": [
    {
      "event_time": "2025-09-23T15:00:00Z",
      "anomaly_type": "heat_wave",
      "observed_temperature": 30.0,
      "expected_temperature": 18.0,
      "temp_deviation": 12.0,
      "observed_windspeed": null,
      "expected_windspeed": null,
      "wind_deviation": null
    }
  ],
  "total_anomalies": 1,
  "updated_at": "2025-09-23T15:05:00Z"
}
```

## üìÅ Fichiers cr√©√©s

### Scripts principaux

1. **`anomaly_detector.py`**
   - Job Spark Structured Streaming
   - D√©tection d'anomalies en temps r√©el
   - Jointure Batch vs Speed
   - Publication Kafka + sauvegarde HDFS

2. **`run_anomaly_detector.sh`**
   - Script de lancement automatique
   - V√©rification des pr√©requis
   - Cr√©ation du topic Kafka
   - Nettoyage des checkpoints
   - Lancement du job Spark

3. **`create_anomalies_topic.sh`**
   - Cr√©ation du topic Kafka `weather_anomalies`

## üöÄ Utilisation

### Pr√©requis

1. **Profils saisonniers enrichis** (Exercice 12)
   ```bash
   # T√©l√©charger les donn√©es historiques
   python3 weather_history_loader.py --city Paris --country France --years 10
   
   # G√©n√©rer les profils enrichis
   ./run_profile_enricher.sh
   ```

2. **Topic `weather_transformed` actif**
   - Le producteur m√©t√©o doit √™tre en cours d'ex√©cution
   - Le transformateur Spark doit √™tre actif

### D√©marrage rapide

```bash
# 1. Cr√©er le topic (automatique dans run_anomaly_detector.sh)
./create_anomalies_topic.sh

# 2. Lancer le d√©tecteur d'anomalies
./run_anomaly_detector.sh
```

### Options avanc√©es

```bash
# Lancer avec des seuils personnalis√©s
docker exec -it pyspark_notebook spark-submit \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0 \
  --conf spark.sql.streaming.checkpointLocation=/tmp/checkpoint/anomaly_detector_kafka \
  /tmp/anomaly_detector.py \
  --kafka-servers kafka:9092 \
  --input-topic weather_transformed \
  --output-topic weather_anomalies \
  --hdfs-path /hdfs-data \
  --temp-threshold 7.0 \
  --wind-threshold 2.5
```

### Consommer les anomalies depuis Kafka

```bash
# Consommer les anomalies en temps r√©el
python3 kafka_consumer.py weather_anomalies
```

### V√©rifier les anomalies dans HDFS

```bash
# Lister les anomalies sauvegard√©es
docker exec namenode hdfs dfs -ls -R /hdfs-data/*/anomalies/

# Afficher les anomalies d'une ville/mois
docker exec namenode hdfs dfs -cat /hdfs-data/France/Paris/anomalies/2025/09/anomalies.json | python3 -m json.tool
```

## üîç Exemples de d√©tection

### Exemple 1 : Vague de chaleur

**Donn√©es temps r√©el** :
- Temp√©rature : 35¬∞C
- Date : 15 janvier (hiver)

**Profil historique (janvier)** :
- Temp√©rature moyenne : 5¬∞C
- √âcart-type : 3¬∞C

**D√©tection** :
- √âcart : 35 - 5 = 30¬∞C > 5¬∞C ‚úÖ
- √âcart : 30¬∞C > 2 √ó 3¬∞C = 6¬∞C ‚úÖ
- **Anomalie d√©tect√©e** : `heat_wave`

### Exemple 2 : Temp√™te de vent

**Donn√©es temps r√©el** :
- Vent : 25 m/s

**Profil historique (mois actuel)** :
- Vent moyen : 8 m/s
- √âcart-type : 4 m/s

**D√©tection** :
- √âcart : 25 - 8 = 17 m/s
- Seuil : 2 √ó 4 = 8 m/s
- 17 m/s > 8 m/s ‚úÖ
- **Anomalie d√©tect√©e** : `wind_storm`

### Exemple 3 : Alerte inattendue

**Donn√©es temps r√©el** :
- Alerte chaleur : `level_2` (canicule)

**Profil historique (mois actuel)** :
- Probabilit√© d'alerte : 2%

**D√©tection** :
- Alerte pr√©sente : ‚úÖ
- Probabilit√© historique < 10% : ‚úÖ
- **Anomalie d√©tect√©e** : `unexpected_alert`

## üìä Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  weather_transformed ‚îÇ  ‚Üê Speed Layer (Kafka)
‚îÇ     (Kafka Topic)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îÇ Streaming
           ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Spark Streaming    ‚îÇ
‚îÇ  Anomaly Detector   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
           ‚îÇ
           ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
           ‚îÇ                 ‚îÇ
           ‚ñº                 ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ seasonal_profiles‚îÇ  ‚îÇ  Jointure Batch vs   ‚îÇ
‚îÇ    (HDFS)        ‚îÇ  ‚îÇ       Speed          ‚îÇ
‚îÇ  Batch Layer     ‚îÇ  ‚îÇ                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                                 ‚îÇ
                                 ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ  D√©tection Anomalies   ‚îÇ
                    ‚îÇ  (Seuils configurables)‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ                             ‚îÇ
                ‚ñº                             ‚ñº
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ weather_anomalies‚îÇ        ‚îÇ  /hdfs-data/.../     ‚îÇ
    ‚îÇ   (Kafka Topic)  ‚îÇ        ‚îÇ  anomalies.json      ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## ‚öôÔ∏è Configuration

### Seuils par d√©faut

- **Temp√©rature** : ¬±5¬∞C ou 2 √©carts-types
- **Vent** : 2 √©carts-types
- **Alertes** : Probabilit√© historique < 10%

### Personnalisation

Modifiez les arguments dans `run_anomaly_detector.sh` :

```bash
--temp-threshold 7.0    # Seuil temp√©rature en ¬∞C
--wind-threshold 2.5    # Seuil vent en √©carts-types
```

## üîß D√©pannage

### Aucun profil saisonnier trouv√©

```
‚ö†Ô∏è  Aucun profil saisonnier enrichi trouv√© dans HDFS
   Ex√©cutez d'abord l'exercice 12 pour cr√©er les profils enrichis
```

**Solution** :
```bash
# 1. T√©l√©charger les donn√©es historiques
python3 weather_history_loader.py --city Paris --country France --years 10

# 2. G√©n√©rer les profils enrichis
./run_profile_enricher.sh

# 3. Relancer le d√©tecteur
./run_anomaly_detector.sh
```

### Aucune anomalie d√©tect√©e

**V√©rifications** :
1. Le producteur m√©t√©o est-il actif ?
2. Le transformateur Spark est-il actif ?
3. Les donn√©es arrivent-elles dans `weather_transformed` ?
4. Les seuils sont-ils trop stricts ?

**Test** :
```bash
# Consommer weather_transformed pour v√©rifier les donn√©es
python3 kafka_consumer.py weather_transformed

# V√©rifier les profils charg√©s
docker exec namenode hdfs dfs -cat /hdfs-data/France/Paris/seasonal_profile_enriched/2020/profile.json | python3 -m json.tool
```

### Erreur de checkpoint

```
Multiple streaming queries are concurrently using file:/tmp/checkpoint/...
```

**Solution** :
```bash
# Nettoyer les checkpoints
docker exec pyspark_notebook rm -rf /tmp/checkpoint/anomaly_detector_kafka
docker exec pyspark_notebook rm -rf /tmp/checkpoint/anomaly_detector_hdfs

# Relancer
./run_anomaly_detector.sh
```

## üìà M√©triques et monitoring

### Statistiques affich√©es

Le d√©tecteur affiche en temps r√©el :
- Nombre de messages trait√©s par batch
- Nombre d'anomalies d√©tect√©es
- D√©tails des anomalies (ville, type, √©cart)

### Exemple de sortie

```
üì® Batch 0: 10 message(s), 2 anomalie(s) d√©tect√©e(s)
üö® Anomalies d√©tect√©es:
+------+-------+-------------+--------------+-------------+
|city  |country|anomaly_type |temp_deviation|wind_deviation|
+------+-------+-------------+--------------+-------------+
|Paris |France |heat_wave    |12.5          |null         |
|Paris |France |wind_storm   |null          |8.3          |
+------+-------+-------------+--------------+-------------+
```

## üéì Concepts cl√©s

### Lambda Architecture

- **Speed Layer** : Traitement en temps r√©el (Kafka + Spark Streaming)
- **Batch Layer** : Donn√©es historiques pr√©-calcul√©es (HDFS)
- **Serving Layer** : Jointure des deux pour enrichir les donn√©es temps r√©el

### D√©tection d'anomalies

- **M√©thode statistique** : Comparaison avec moyenne et √©cart-type
- **Seuils configurables** : Adaptation selon le contexte
- **Types multiples** : Temp√©rature, vent, alertes

### Spark Structured Streaming

- **Jointure avec donn√©es statiques** : Broadcast des profils historiques
- **Traitement par batch** : Fen√™tres de traitement configurables
- **Checkpointing** : Gestion de l'√©tat pour la reprise

## üìö R√©f√©rences

- [Spark Structured Streaming](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [Lambda Architecture](https://en.wikipedia.org/wiki/Lambda_architecture)
- [Anomaly Detection](https://en.wikipedia.org/wiki/Anomaly_detection)

## ‚úÖ Checklist de validation

- [ ] Profils saisonniers enrichis disponibles dans HDFS
- [ ] Topic `weather_transformed` actif avec donn√©es
- [ ] Topic `weather_anomalies` cr√©√©
- [ ] D√©tecteur d'anomalies lanc√© et fonctionnel
- [ ] Anomalies publi√©es dans Kafka
- [ ] Anomalies sauvegard√©es dans HDFS
- [ ] Structure HDFS correcte : `/hdfs-data/{country}/{city}/anomalies/{year}/{month}/`

---

**Exercice 13 termin√© !** üéâ

Le syst√®me de d√©tection d'anomalies est op√©rationnel et pr√™t √† √™tre utilis√© par les dashboards frontend.
